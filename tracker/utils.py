import csv
from io import BytesIO
from datetime import timedelta
from django.http import HttpResponse
from django.utils import timezone
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from .models import ActivityEntry
import requests
from bs4 import BeautifulSoup
import feedparser

# --- PDF: —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —à—Ä–∏—Ñ—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü—ã ---
# –ó–∞–º–µ–Ω–∏—Ç–µ –ø—É—Ç—å –Ω–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É DejaVuSans.ttf –Ω–∞ –≤–∞—à–µ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ
pdfmetrics.registerFont(TTFont('DejaVuSans', r'C:\coreflow_project\templates\tracker\DejaVuSans.ttf'))

def export_entries_csv(user):
    # CSV —Å BOM –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ Excel
    response = HttpResponse(content_type='text/csv; charset=utf-8')
    response['Content-Disposition'] = 'attachment; filename="activities.csv"'
    response.write('\ufeff')  # BOM

    writer = csv.writer(response)
    writer.writerow(['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ù–∞—á–∞–ª–æ', '–ö–æ–Ω–µ—Ü', '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–º–∏–Ω)', '–ó–∞–º–µ—Ç–∫–∞'])
    for entry in ActivityEntry.objects.filter(user=user).order_by('-start'):
        writer.writerow([
            entry.get_category_display(),
            entry.start.isoformat(),
            entry.end.isoformat(),
            entry.duration_minutes,
            entry.note
        ])
    return response

def export_entries_pdf(user):
    entries = ActivityEntry.objects.filter(user=user).order_by('-start')
    totals = {'study':0,'rest':0,'sleep':0,'other':0}
    for e in entries:
        totals[e.category] += e.duration_minutes

    response = HttpResponse(content_type='application/pdf')
    response['Content-Disposition'] = 'attachment; filename="activities_report.pdf"'
    buffer = BytesIO()
    p = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    p.setFont('DejaVuSans', 16)
    p.drawString(50, height-50, 'TimeSaver ‚Äî –û—Ç—á—ë—Ç –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—è–º')
    p.setFont('DejaVuSans', 12)
    p.drawString(50, height-80, f'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user.username}')
    p.drawString(50, height-100, f'–î–∞—Ç–∞: {timezone.localtime().date().isoformat()}')

    # Totals —Å –≥—Ä–∞—Ñ–∏–∫–æ–º
    y = height - 140
    p.setFont('DejaVuSans', 12)
    p.drawString(50, y, '–ò—Ç–æ–≥–æ (–º–∏–Ω):')
    y -= 20
    max_total = max(totals.values()) if totals.values() else 1
    bar_max_width = 300
    for k,label in [('study','–£—á—ë–±–∞'),('rest','–û—Ç–¥—ã—Ö'),('sleep','–°–æ–Ω'),('other','–î—Ä—É–≥–æ–µ')]:
        val = totals.get(k,0)
        p.drawString(60, y, f'{label}: {val} –º–∏–Ω')
        bar_w = int((val / (max_total if max_total>0 else 1)) * bar_max_width)
        p.setFillColorRGB(0.2,0.6,0.86)
        p.rect(200, y-4, bar_w, 10, fill=1)
        y -= 20
        if y < 120:
            p.showPage()
            y = height - 50

    # –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π
    p.showPage()
    p.setFont('DejaVuSans', 14)
    p.drawString(50, height-50, '–°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π')
    p.setFont('DejaVuSans', 10)
    y = height - 80
    for e in entries:
        line = f"{e.get_category_display()} | {e.start.strftime('%Y-%m-%d %H:%M')} - {e.end.strftime('%H:%M')} | {e.duration_minutes} –º–∏–Ω | {e.note}"
        p.drawString(50, y, line[:130])
        y -= 14
        if y < 40:
            p.showPage()
            y = height - 40

    p.save()
    pdf = buffer.getvalue()
    buffer.close()
    response.write(pdf)
    return response

def generate_advice(user):
    now = timezone.now()
    week_ago = now - timedelta(days=7)
    entries = ActivityEntry.objects.filter(user=user, start__gte=week_ago)

    total = {'–£—á—ë–±–∞': 0, '–û—Ç–¥—ã—Ö': 0, '–°–æ–Ω': 0}
    for e in entries:
        category_label = e.get_category_display()
        if category_label in total:
            total[category_label] += (e.end - e.start).total_seconds() / 3600

    advice = []

    study = total['–£—á—ë–±–∞']
    rest = total['–û—Ç–¥—ã—Ö']
    sleep = total['–°–æ–Ω']

    if study < 10:
        advice.append("–¢—ã —É—á–∏–ª—Å—è –º–µ–Ω—å—à–µ 10 —á–∞—Å–æ–≤ –∑–∞ –Ω–µ–¥–µ–ª—é. –ü–æ–ø—Ä–æ–±—É–π –ø–æ—Å—Ç–∞–≤–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–µ–ª–∏ –Ω–∞ –¥–µ–Ω—å.")
    if rest > 15:
        advice.append("–û—Ç–¥—ã—Ö ‚Äî —ç—Ç–æ —Ö–æ—Ä–æ—à–æ, –Ω–æ, –≤–æ–∑–º–æ–∂–Ω–æ, —Ç—ã –æ—Ç–≤–ª–µ–∫–∞–µ—à—å—Å—è —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç–æ. –ü–æ–ø—Ä–æ–±—É–π –º–µ—Ç–æ–¥ Pomodoro.")
    if sleep < 40:
        advice.append("–¢—ã —Å–ø–∏—à—å –º–µ–Ω—å—à–µ 6 —á–∞—Å–æ–≤ –≤ —Å—É—Ç–∫–∏. –≠—Ç–æ –º–æ–∂–µ—Ç —É—Ö—É–¥—à–∏—Ç—å –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é.")
    if 15 <= study <= 25 and 35 <= sleep <= 50 and rest <= 10:
        advice.append("–û—Ç–ª–∏—á–Ω—ã–π –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —É—á—ë–±–æ–π, –æ—Ç–¥—ã—Ö–æ–º –∏ —Å–Ω–æ–º üí™ –ü—Ä–æ–¥–æ–ª–∂–∞–π –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ!")

    if not advice:
        advice.append("–î–∞–Ω–Ω—ã—Ö –ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –¥–æ–±–∞–≤—å –±–æ–ª—å—à–µ –∑–∞–ø–∏—Å–µ–π, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.")

    return advice

# --- –ü–æ–≥–æ–¥–∞ ---
def get_weather(city="Yekaterinburg"):
    api_key = "7549b3ff11a7b2f3cd25b56d21c83c6a"  # –≤—Å—Ç–∞–≤—å—Ç–µ —Å–≤–æ–π –∫–ª—é—á
    url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&units=metric&lang=ru&appid={api_key}"
    data = requests.get(url).json()
    weather = {
        'city': city,
        'temp': data['main']['temp'],
        'description': data['weather'][0]['description'],
        'icon': data['weather'][0]['icon'],
    }
    return weather

# --- –ù–æ–≤–æ—Å—Ç–∏ URFU ---
def get_urfu_news():
    url = "https://urfu.ru/ru/news/"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    news_items = []
    for item in soup.select('a.news-item-link')[:5]:  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –Ω–æ–≤–æ—Å—Ç–µ–π
        title = item.get_text(strip=True)
        link = "https://urfu.ru" + item['href']
        news_items.append({'title': title, 'link': link})
    return news_items

URFU_NEWS_RSS = "https://urfu.ru/ru/news/rss/"

def get_urfu_news(limit=5):
    feed = feedparser.parse(URFU_NEWS_RSS)
    news_list = []
    for entry in feed.entries[:limit]:
        news_list.append({
            'title': entry.title,
            'link': entry.link,
            'published': entry.published if 'published' in entry else '',
            'summary': entry.summary if 'summary' in entry else ''
        })
    return news_list